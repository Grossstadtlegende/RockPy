import os
from datetime import datetime

import pandas as pd
import numpy as np
import pint

import RockPy
from RockPy import ureg
import RockPy.core.ftype
from RockPy.tools.pandas_tools import xyz2dim, dim2xyz, correct_dec_inc
import RockPy.tools.compute as Rc

class Cit(RockPy.core.ftype.Ftype):
    ''' Ftype object that contains data read in from 'cif' files.

    Parameters
    ----------
        data (:obj:`pandas.DataFrame`): Data contained in the cif (or. UP) files. Note: units are converted to SI
            internally
        corrections (dict): A dictionary of the dec, inc values for all possible orientations (below, towards) when
            measuring in the UP position.
        in_units (dict(:obj:`pint.ureg`)): units from used in the data file
        out_units (dict(:obj:`pint.ureg`)): units used to export the data
        units (dict(:obj:`pint.ureg`)): units used internally (should be SI units)
        datacolumns (tuple(str)): names of all the columns should be the same as `self.data.columns`
        
    Notes
    -----
        Data columns:
            `'mtype', 'level', 'geo_dec', 'geo_inc', 'strat_dec', 'strat_inc', 'intensity', 'ang_err',
                   'plate_dec', 'plate_inc', 'std_x', 'std_y', 'std_z', 'user', 'date', 'time'`
    See Also
    --------
        For more information on `attributes` see :py:class:`RockPy.core.ftype.Ftype`
    '''
    datacolumns = ('mtype', 'level', 'geo_dec', 'geo_inc', 'strat_dec', 'strat_inc', 'intensity', 'ang_err',
                   'plate_dec', 'plate_inc', 'std_x', 'std_y', 'std_z', 'user', 'date', 'time')

    # dec/ inc values for (below, towards) combinations
    corrections = {"TW": (0, 0),
                   "TN": (90, 0),
                   "TE": (180, 0),  #
                   "TS": (270, 0),
                   "ET": (0, 90),
                   "ST": (90, 90),
                   "WT": (180, 90),
                   "NT": (270, 90),
                   "BE": (0, 180),  #
                   "BS": (90, 180),
                   "BW": (180, 180),
                   "BN": (270, 180),
                   ####
                   "WB": (0, 270),
                   "NB": (90, 270),
                   "EB": (180, 270),
                   "WS": (270, 270),
                   }

    in_units = {'geo_dec': ureg('degree'),
                'geo_inc': ureg('degree'),
                'strat_dec': ureg('degree'),
                'strat_inc': ureg('degree'),
                'intensity': ureg('emu'),
                'ang_err': ureg('degree'),
                'plate_dec': ureg('degree'),
                'plate_inc': ureg('degree'),
                'std_x': ureg('emu'),
                'std_y': ureg('emu'),
                'std_z': ureg('emu'),
                'x': ureg('emu'),
                'y': ureg('emu'),
                'z': ureg('emu')}

    out_units = in_units

    units = {'geo_dec': ureg('degree'),
             'geo_inc': ureg('degree'),
             'strat_dec': ureg('degree'),
             'strat_inc': ureg('degree'),
             'intensity': ureg('ampere meter ^2'),
             'ang_err': ureg('degree'),
             'plate_dec': ureg('degree'),
             'plate_inc': ureg('degree'),
             'std_x': ureg('ampere meter ^2'),
             'std_y': ureg('ampere meter ^2'),
             'std_z': ureg('ampere meter ^2'),
             'x': ureg('ampere meter ^2'),
             'y': ureg('ampere meter ^2'),
             'z': ureg('ampere meter ^2')}

    def __init__(self, dfile,
                 snames=None, reload=False,
                 mdata=None, create_minfo=True,
                 level_unit='gauss', dialect=None,
                 **kwargs):
        """
        Constructor for the Cif file type. Reads cif files as generated by the 2G rapid system, for example.
        Generally agnostic to the measurement type.

        Args:
            dfile (str): full path to file on HD
            snames (str, optional): defaults to None
                sample name
            reload (bool, optional): defaults to True.
                if True the file will be re-imported from HD
                if False RockPy will attempt to read the file from cache
            mdata (:obj:`pd.DataFrame`, optional): defaults to None. Used for creation of cif from several
                files (i.e. UP) using from_file method
            create_minfo (bool, optional): if False creation of ImportHelper object is suppressed;
                if True RockPy will try to create ImportHelper object
            level_unit(str, optional): defaults to 'G'. Determines the unit for the level. May be ËšC, G, ...
            **kwargs: arbitrary keyword arguments
        """

        # set the level units
        if level_unit == 'gauss':
            self.in_units['level'] = ureg('gauss')
            self.units['level'] = ureg('tesla')
        if level_unit == 'celsius':
            self.in_units['level'] = ureg('celsius')
            self.units['level'] = ureg('kelvin')

        # call the ftype constructor
        super().__init__(dfile, snames=snames,
                         dialect=None, reload=reload,
                         mdata=mdata, create_minfo=create_minfo,
                         **kwargs)

        # read the header file if none was specified (e.g. through read_rapid)
        if self.header is None:
            self.header = self._read_header(self.raw_data[:2])

        self.data = self._add_missing_levels(self.data)

    """ staticmethods """

    @staticmethod
    def _separate_row(raw_data):
        """ Strips each line of the 'cif' file into its values.

        Args:
            raw_data (list(str)): List of strings from read_file

        Returns:

        """
        rows = []
        header_rows = []

        for idx, row in enumerate(raw_data):
            if row.startswith('#'):
                continue
            # data rows start at idx 2
            if idx > 1:
                # index of first number
                num_index = min(i for i, v in enumerate(row) if v.isnumeric())

                # shift index for direction to be displayed in mtype
                if row.startswith('UAFX'):
                    num_index += 1

                mtype = row[:num_index].rstrip()
                if not row[num_index:6]:
                    level = 0
                else:
                    level = int(row[num_index:6])

                # other columns are separate by whitespace -> split(' ')
                values = [i for i in row[6:].split(' ') if i]

                # set string variables
                user, date, time = values[11:14]

                # set float variables
                geo_dec, geo_inc, strat_dec, strat_inc, intensity, ang_err, plate_dec, plate_inc, std_x, std_y, std_z = np.array(
                    values[:11]).astype(float)

                rows.append(
                    [mtype, level, geo_dec, geo_inc, strat_dec, strat_inc, intensity, ang_err, plate_dec, plate_inc,
                     std_x, std_y, std_z, user, date, time])
            else:
                header_rows.append(row.rstrip())
        return rows, header_rows

    @staticmethod
    def _return_mean_from_UP_file(df, subtract_holder=True):
        """ takes a DataFrame created from reading in an (UP) file (see. read_UP_files)

        This method subtracts the holder measurements and calculates the mean from the 4 measurement positions.
        It returns a new :obj:`pandas.DataFrame` with the data.

        Args:
            df (:obj:`pandas.DataFrame`): with the raw data.
        """
        means = {'S': None, 'H': None, 'Z': None}
        stdevs = {'S': None, 'H': None, 'Z': None}

        for mtype in ('S', 'H'):
            d = df[df['MsmtType'] == mtype]

            mean = d.groupby(d.index).mean()
            std = d.groupby(d.index).std()

            means[mtype] = mean
            stdevs[mtype] = std

        out = pd.DataFrame(
            columns=['mtype', 'level', 'geo_dec', 'geo_inc', 'strat_dec', 'strat_inc', 'intensity', 'ang_err',
                     'plate_dec', 'plate_inc', 'std_x', 'std_y', 'std_z', 'user', 'date', 'time', 'sample',
                     'direction'],
            index=sorted(set(df.index)))

        out['direction'] = df.iloc[0]['Direction']

        out['level'] = df.iloc[0]['level']
        out['sample'] = df.iloc[0]['Sample']
        out['mtype'] = df.iloc[0]['mtype']
        out['mtype'] = df.iloc[0]['mtype']
        # add standard deviations to df
        out['std_x'] = stdevs['S']['x']
        out['std_y'] = stdevs['S']['y']
        out['std_z'] = stdevs['S']['z']

        # calculate Dec/Inc standard deviations # todo calculate this properly i.e. alpha 95 or something
        out['ang_err'] = stdevs['S']['D']

        if subtract_holder:
            out[['x', 'y', 'z']] = Cif._correct_holder(means['S'][['x', 'y', 'z']], means['H'][['x', 'y', 'z']])
        return out

    @staticmethod
    def _correct_holder(sample_means, holder_means):
        """ subtracts holder measurement

        Args:
            sample_means (:obj:`pandas.Series`): 'x', 'y' and 'z' values of the sample
            holder_means (:obj:`pandas.Series`): 'x', 'y' and 'z' values of the holder

        Returns:
            :obj:`pandas.Series`: Holder corrected 'x', 'y' and 'z' values
        """
        corrected = sample_means - holder_means
        return corrected

    def _write_cif_line(self, series):
        """ Writes one cit formatted line.

        Args:
            series (:obj:`pandas.Series`): Thedata for the line, as a pandas Series from the data Dataframe.

        Returns:
            str: string formatted to cit format

        See Also:
            :py:meth:`RockPy.core.ftype.Ftype.read_file` docstring for information on the exact formatting.
        """

        series = series[1].copy() #create copy of the series, dont work with original data

        #todo convert back to original units using pint

        # convert back to out_units
        level = int(series['level'] * 10000)

        for l in series.index:
            if not l in self.out_units:
                continue
            try:
                series[l] *= (1 * self.units[l]).to(self.out_units[l]).magnitude
            except pint.errors.DimensionalityError:
                if self.units[l] == 'Tesla' and self.out_units[l] == 'gauss':
                    series[l] *= 10000

        mtype = series['mtype']
        # series[['std_x', 'std_y', 'std_z', 'intensity']] *=  # to emu
        # series[['intensity']] *= 1e-5  # std is saved in 10^-5 emu


        timedate = pd.to_datetime(series['date'] + ' ' + series['time'])

        columns = ['geo_dec', 'geo_inc', 'strat_dec', 'strat_inc', 'intensity', 'ang_err',
                   'plate_dec', 'plate_inc', 'std_x', 'std_y', 'std_z', 'user']
        # todo check the formatting
        formats = {'mtype': '{:<2}', 'level': '{:>4}',
                   'geo_dec': '{:>5.1f}', 'geo_inc': '{:>5.1f}', 'strat_dec': '{:>5.1f}', 'strat_inc': '{:>5.1f}',
                   'intensity': '{:.2E}', 'ang_err': '{:05.1f}', 'plate_dec': '{:>5.1f}', 'plate_inc': '{:>5.1f}',
                   'std_x': '{:>.6f}', 'std_y': '{:>.6f}', 'std_z': '{:>.6f}',
                   'user': '{:>7}', 'date': '{:>4}', 'time': '{:>4}'}

        if mtype == 'NRM' or mtype == 'ARM':
            formats['mtype'] = "{:<3}"
            formats['level'] = '{:>3}'
            level = ''

        if "UAFX" in mtype:
            formats['mtype'] = "{:<5}"
            formats['level'] = '{:>1}'
            level = str(level)[-1]

        start = ''.join([formats['mtype'].format(mtype), formats['level'].format(level), ' '])
        rest = ' '.join(formats[fmt].format(series[fmt]) for fmt in columns)
        date = timedate.strftime(' %Y-%m-%d')
        time = timedate.strftime(' %H:%M:%S')

        return start + rest + date + time + ' '

    """ classmethods """

    @classmethod
    def _read_header(self, header_rows):
        """ Reads the header of a cit file.

        In the first line the first four characters are the locality id, the next 9 the sample id, and the remainder
        (to 255) is a sample comment.

        In the second line, the first character is ignored, the next 6 comprise the stratigraphic level
        (usually in meters). The remaining fields are all the same format: first character ignored (should be a blank
        space) and then 5 characters used. These are the core strike, core dip, bedding strike, bedding dip, and core
        volume or mass. Conventions are discussed below. CIT format can include fold axis and plunge, which at present
        is unused.

        Args:
            header_rows (list(str)): List of str from the `read_file` method.

        """
        locality = header_rows[0][:4].strip(' ')
        sample_id = header_rows[0][4:13].strip(' ')

        widths = [(1, 7), (8, 13), (14, 19), (20, 25), (26, 31), (32, 37)]
        labels = ['stratigraphic_level',
                  'core_strike', 'core_dip',
                  'bedding_strike', 'bedding_dip',
                  'core_volume_or_mass']

        lw_dict = dict(zip(labels, widths))

        header = pd.DataFrame(index=[sample_id])
        header['locality_id'] = locality
        for label in lw_dict:
            v = header_rows[1][lw_dict[label][0]:lw_dict[label][1]].strip(' ')

            if v:
                header.loc[sample_id, label] = float(v)
            else:
                header.loc[sample_id, label] = None
        header.index.name = 'sample_id'
        return header

    @classmethod
    def _add_missing_levels(cls, data):
        """ Adds the correct level for a UAFX measurement.

        Adds the correct level for a UAFX measurement, assuming it is the same level as the previous AF measurement.

        Returns:
            :obj:`pandas.Dataframe`: with a additional column 'old_levels'

        Warnings:
            Assuming that the previous AF step is the same as the UAFX steps, may be wrong.
        """
        data = data.copy()
        
        AF_index = [(i, v) for i, v in enumerate(data['mtype']) if v == 'AF']

        new_levels = data['level'].values
        #
        # # just in case make a copy of the old levels for reference
        # data['old_levels'] = old_levels

        # new_levels = old_levels
        for idx, level in enumerate(new_levels):
            # if 'ARM'  in data['mtype'].iloc[idx]:
            #     level = 0
            if 'UAFX' in data['mtype'].iloc[idx]:
                prev_AF_idx = max(i for i, v in AF_index if i < idx)
                level = data['level'].iloc[prev_AF_idx]
            new_levels[idx] = level
        data.loc[:, 'level'] = new_levels
        return data

    @classmethod
    def _read_UP_file(cls, dfile, sample_id, reload=False):
        """ Read function for Up files.

        This function reads in the UP file and returns a pandas.DataFrame with the data in SI units.

        Args:
            dfile (str): full path of the file on HD
            sample_id (str): In case more than one sample is in the file, this filters for the right sample
            reload (bool): defaults to False. If `True` the file will be reloaded.
                If `False` the file will be read only from the cached copy in
                :obj:`RockPy.ftype.cif.Cif.imported_files[dfile]`.

        Returns:
            :obj:`pandas.DataFrame`: in SI units

        TODO:
            use _to_SI_units instead of these calculations
        """
        if dfile not in cls.imported_files or reload:
            cls.imported_files[dfile] = cls._read_raw_UP_file(dfile)

        out = cls.imported_files[dfile].copy() # todo does this have to be a copy?
        # check if the sample is in the data
        if not sample_id in set(out['Sample']):
            RockPy.log.warning('Could not find sample_id << {} >> in file << {} >.! '
                             'Please check correct spelling'.format(sample_id, os.path.basename(dfile)))
            return

        sdata = out.loc[out.Sample == sample_id].copy()

        # convert to cif file 10^-5 emu
        sdata.loc[:, ['X', 'Y', 'Z']] *= 1e-5

        sdata = sdata.rename(columns={"X": "X_", "Y": "Y_", "Z": "Z_"})
        # create a copy of the Z values
        sdata.loc[:, 'z'] = sdata['Z_']

        # rotate measurements into sample coordinates
        sdata = cls._rotate_UP_measurements(sdata)

        # calculate dec, inc and moment
        sdata = xyz2dim(sdata, colX='x', colY='y', colZ='z', colD='D', colI='I', colM='M')

        sdata = sdata.set_index('datetime')
        dfile = os.path.basename(dfile)
        sdata.loc[:, 'dfile'] = dfile

        mtype = ''.join([n for n in dfile.split('.')[0] if not n.isnumeric()]).rstrip()
        level = ''.join([n for n in dfile.split('.')[0] if n.isnumeric() if n])

        if 'UAFX' in mtype:
            mtype += level[0]
            level = level[1:]
        if mtype == 'NRM':
            level = 0

        sdata.loc[:, 'mtype'] = mtype

        try:
            sdata.loc[:, 'level'] = int(level)
        except:
            sdata.loc[:, 'level'] = 0

        return sdata

    @classmethod
    def _rotate_UP_measurements(cls, sdata):
        """ Rotates the 2,3,4 measurement of an UP file so they align with the 1st.

        Due to the sample handler rotation, the raw data of the 2,3, and 4 th positions in the UP file are rotated.
        This method rotates 2,3,4 into the same orientation as 1.

        Args:
            sdata (:obj:`pandas.DataFrame`): The unrotated data

        Returns:
            sdata (:obj:`pandas.DataFrame`): The rotated data

        Notes:
            - For some reason, the y component has to be multiplied by -1. Otherwise the values from the UP files and the `cif` file generated by the rapid system are not the same.
            - If the measurement direction is 'DOWN' instead of up, y and z values are multiplied by -1
        """
        for idx, v in sdata.iterrows():
            x, y = v[['X_', 'Y_']].values

            if v['MsmtNum'] == 1:
                sdata.loc[idx, 'x'] = x
                sdata.loc[idx, 'y'] = y
            elif v['MsmtNum'] == 2:
                sdata.loc[idx, 'x'] = y
                sdata.loc[idx, 'y'] = -x
            elif v['MsmtNum'] == 3:
                sdata.loc[idx, 'x'] = -x
                sdata.loc[idx, 'y'] = -y
            elif v['MsmtNum'] == 4:
                sdata.loc[idx, 'x'] = -y
                sdata.loc[idx, 'y'] = x

            sdata.loc[idx, 'y'] *= -1

            if v['Direction'] == 'D':
                sdata.loc[idx, 'y'] *= -1
                sdata.loc[idx, 'z'] *= -1
        return sdata

    @classmethod
    def _read_raw_UP_file(cls, dfile):
        """ Reads the raw UP file and formats the values

        Args:
            dfile (str): full path to file on HD

        Returns:
            :obj:`pandas.DataFrame`: Dataframe with raw_data
        """
        with open(dfile) as raw_data:
            raw_data = raw_data.readlines()
        header = raw_data[0]
        raw_data = [n.rstrip().replace(',', '|') for n in raw_data]
        # in case of weird double <CR> symbols
        raw_data = [i for i in raw_data if i]

        raw_data = [n.split('|') for n in raw_data]
        header = header.rstrip().replace(',', '|')
        header = header.split('|')
        header.append('datetime')
        raw_data = [[n[0], n[1], int(n[2]), n[3], int(n[4]), int(n[5]), float(n[6]), float(n[7]), float(n[8]),
                     pd.to_datetime(n[9])] for n in raw_data[1:]]
        return pd.DataFrame(columns=header, data=raw_data)

    @classmethod
    def from_rapid(cls, files_or_folder,
                   sample_id, locality_id='',
                   core_strike=0., core_dip=0.,
                   bedding_strike=0., bedding_dip=0.,
                   core_volume_or_mass=1,
                   stratigraphic_level='', comment='', user='lancaster',
                   subtract_holder=True,
                   reload=False):
        """
        reads Up files or folder containing Up-files and constructs a cif-like object.

        Args:
            files_or_folder (str, list): if `files_or_folder` is a folder, all files will be loaded using `os.listdir`
                if `files_or_folder` is a list of files, each file will be loaded
            sample_id (str): The name of the sample in the UP files. This is because there may be more than one sample in the files.
            locality_id (str, optional): defaults to ''. The name of the locality is used for export.
                It is written in the header of the new `sample_id` file.
            core_strike (float, optional):  defaults to 0. Strike of the core with respect to machine coordinates
            core_dip (float, optional):  defaults to 0. Dip of the core with respect to machine coordinates
            bedding_strike (float, optional):  defaults to 0. Strike of the bedding plane
            bedding_dip (float, optional): defaults to 0. Dip of the bedding plane
            core_volume_or_mass (float, optional): defaults to 1. This, again is used for export purposes only.
                The `cif` files exported from the rapid system are normalized by either the mass or the volume of the
                sample, which is given in the file header. Thus it needs to be specified if normalization is desired.
            stratigraphic_level (float, optional): defaults to ''. Used in export
            comment (str, optional): defaults to ''. Used in export
            user (str, optional): defaults to 'lancaster'. Used in export
            reload (bool, optional): defaults to False. If False, the file will be read every time the `from_rapid`
                method is called. If True, a cached version of the file is used, speeding up the code somewhat.

        Examples:
            Creating an object::

            >> import RockPy
            >> cif_object = RockPy.ftype.cif.Cif.from_rapid(
            >>     files_or_folder = "location_of_the_files_on_HD",
            >>     sample_id = 'sample',
            >>     )

            This will now read in all files in the folder, or all specified files (list).

        Returns:
            :obj:`RockPy.ftype.cif.Cif`
        """

        if os.path.isdir(files_or_folder):
            files = [os.path.join(files_or_folder, f) for f in os.listdir(files_or_folder)]
        else:
            files = RockPy.to_tuple(files_or_folder)

        files = sorted([f for f in files if (f.endswith('UP') or f.endswith('DOWN'))])

        # read all the files , create list of Dataframes
        raw_df = []
        for i, dfile in enumerate(files):
            # print('reading file << {:>20} >> {:>4} of {:>4}'.format(os.path.basename(dfile), i, len(files)), end='\r')
            readdf = cls._read_UP_file(dfile, sample_id, reload=reload)

            if readdf is not None:
                raw_df.append(readdf)

        average_df = []
        for i, df in enumerate(raw_df):
            # print('averaging file {:>4} of {:>4}'.format(i, len(raw_df)), end='\r')
            average_df.append(cls._return_mean_from_UP_file(df, subtract_holder=subtract_holder))
        if len(average_df) > 1:
            data = pd.concat(average_df)
        else:
            data = average_df[0]

        data = xyz2dim(data, colX='x', colY='y', colZ='z', colI='plate_inc', colD='plate_dec', colM='intensity')

        data = data.sort_index()
        data.index.name = 'datetime'

        data.loc[:, 'user'] = user[:8]
        data.loc[:, 'date'] = data.index.strftime('%Y-%m-%d')
        data.loc[:, 'time'] = data.index.strftime('%H:%M:%S')

        data.loc[:, 'core_dip'] = core_dip
        data.loc[:, 'core_strike'] = core_strike
        data.loc[:, 'bedding_dip'] = bedding_dip
        data.loc[:, 'bedding_strike'] = bedding_strike
        data.loc[:, ["std_x","std_y","std_z"]] *= 1e5

        data = cls._correct_core(data, core_dip, core_strike)

        data = cls._correct_strat(data, bedding_dip, bedding_strike)

        header_lines = cls._write_header(bedding_dip=bedding_dip, bedding_strike=bedding_strike,
                                         core_dip=core_dip, core_strike=core_strike,
                                         sample_id=sample_id, locality_id=locality_id,
                                         core_volume_or_mass=core_volume_or_mass,
                                         stratigraphic_level=stratigraphic_level, comment=comment)
        header = cls._read_header(header_rows=header_lines)
        return cls(dfile='from .UP files', mdata=data, header=header, create_minfo=False)

    @classmethod
    def _mean_levels(self, df, core_dip, core_strike, strat_dip, strat_strike):
        """ Calculates mean of AF, UAFX ... measurement with the same level.

        Calculates the average for (AF, UAFX1, UAFX2, ...) of the same level. Recalcuates the plate, core and strat
        declination and inclinations.


        Args:
            df (:obj:`pandas.DataFrame`): data with AF, UAFX ... measurements
            core_dip (float): Dip of the core
            core_strike (float): Strike of the core
            strat_dip (float):  Stratigraphic dip
            strat_strike (float): Stratigraphic strike

        Returns:
            :obj:`pandas.Series`: averaged data with recalculated geographic and stratigraphic (dec, inc) values

        Notes:
            Is called by `mean_levels' resets self.data with the means.
        """
        df = df.copy()
        index_name = df.index.name
        # make sure the index is datetime
        df = df.reset_index()
        df = df.set_index('level')

        if 'datetime' in df.columns:
            # make sure the data is sorted
            df = df.sort_values('datetime')

        out = df.loc[~np.in1d(df['mtype'], ['UAFX1', 'UAFX2', 'UAFX3'])].copy()
        mean = df.groupby('level').mean()

        out.loc[:, 'x'] = mean.loc[:, 'x']
        out.loc[:, 'y'] = mean.loc[:, 'y']
        out.loc[:, 'z'] = mean.loc[:, 'z']

        out = self._recalc_core_di(out)
        out = self._correct_core(out, core_dip, core_strike)
        out = self._correct_strat(out, strat_dip, strat_strike)

        # reset df to initial index
        out = out.reset_index()
        out = out.set_index(index_name)

        return out

    @classmethod
    def _recalc_core_di(cls, df):
        df = xyz2dim(df, colX='x', colY='y', colZ='z', colI='plate_inc', colD='plate_dec', colM='intensity')
        return df

    @classmethod
    def _correct_wrong_direction(cls, df, core_dip, core_strike, bedding_dip, bedding_strike, **kwargs):
        """
        corrects the measurement, in case the up/down measurement directions were wrongly chosen.

        Returns
        -------

        """
        df = df.copy()

        df['z'] *= -1
        df['y'] *= -1

        df = cls._recalc_core_di(df)
        df = cls._correct_core(df=df, dip=core_dip, strike=core_strike)
        df = cls._correct_strat(df=df, dip=bedding_dip, strike=bedding_strike)

        return df

    @classmethod
    def _correct_core(cls, df, dip, strike):
        """
        Function corrects data for core orientation.
        Wrapper function calling `RockPy.tools.compute.correct_dec_inc`

        Args:
            df (:obj:`pandas.DataFrame`): Data to be corrected
            dip (float): dip to be corrected for
            strike (float): strike to be corrected for

        See also:
            :py:meth:`RockPy.ftypes.cif.Cif._correct_strat`

            :py:func:`RockPy.tools.compute.correct_dec_inc`

        Returns:
            :obj:`pandas.DataFrame`: copy of corrected data

        """

        if isinstance(dip, pd.Series):
            dip = dip.values[0]
        if isinstance(strike, pd.Series):
            strike = strike.values[0]

        cls.log().info(f'Correcting data for core dip ({dip}) and strike ({strike})')
        return correct_dec_inc(df=df, dip=dip, strike=(strike - 90),
                               colI='plate_inc', colD='plate_dec',
                               newD='geo_dec', newI='geo_inc')

    @classmethod
    def _correct_strat(cls, df, dip, strike):
        """
        Function corrects data for stratigraphic orientation.
        Wrapper function calling `RockPy.tools.compute.correct_dec_inc`.

        Args:
            df (:obj:`pandas.DataFrame`): Data to be corrected
            dip (float): dip to be corrected for
            strike (float): strike to be corrected for

        See also:
            :py:meth:`RockPy.ftypes.cif.Cif._correct_core`

            :py:func:`RockPy.tools.compute.correct_dec_inc`

        Returns:
            :obj:`pandas.DataFrame`: copy of corrected data
        """
        if isinstance(dip, pd.Series):
            dip = dip.values[0]
        if isinstance(strike, pd.Series):
            strike = strike.values[0]

        # only warn if calculation happens
        if dip != 0 or strike != 0:
            cls.log().warn(
                f'UNTESTED: Correcting data for stratigraphic dip ({dip}) and strike ({strike}).')

        return correct_dec_inc(df=df, dip=dip, strike=strike,
                               colI='geo_inc', colD='geo_dec',
                               newI='strat_inc', newD='strat_dec')

    @classmethod
    def _write_header(cls, core_strike, core_dip,
                      bedding_strike, bedding_dip,
                      sample_id,
                      core_volume_or_mass=1, locality_id='', stratigraphic_level='', comment=''):
        """
        Returns a list of strings with the correct Cit formatting. Line 1 = locality and sample info,
        line 2 = orientation info

        Parameters
        ----------
        bedding_dip
        bedding_strike
        core_dip
        core_strike
        sample_id
        core_volume_or_mass
        locality_id
        stratigraphic_level
        comment

        Returns
        -------

        """
        if not stratigraphic_level:
            stratigraphic_level = ''

        comment += f' >> RockPy exported {datetime.now().strftime("%Y-%m-%d %H:%M")}'

        out = ['{:<4}{:<9}{}\n'.format(locality_id, sample_id, comment[:255]),
               ' {:>6} {:>5} {:>5} {:>5} {:>5} {:>5}\n'.format(stratigraphic_level, core_strike, core_dip,
                                                               bedding_strike, bedding_dip, core_volume_or_mass),
               ]
        return out

    def read_file(self):
        """
        The sample format is illustrated by the following fragment::

        >>00000000011111111112222222222333333333344444444445555555555666666666677777777778
        >>12345678901234567890123456789012345678901234567890123456789012345678901234567890
        >>erb  1.0A    Sample just above tuff
        >>  113.0 291.0  63.0  43.0  46.0   1.0
        >>NRM     41.2  49.7  91.4  41.0 3.44E-05   5.5 184.1 -13.1  0.0289  0.0270  0.0468
        >>TT 150  46.7  41.3  84.3  33.7 1.79E-05   7.5 189.4 -20.9  0.0188  0.0130  0.0228
        >>TT 225  55.6  36.8  84.5  25.5 1.44E-05   4.0 197.8 -23.3  0.0193  0.0252  0.0171

        It starts with the header rows.

        See Also:
            See _read_header

        The following lines are in the order the demagnetizations were carried out. The first 2 characters (3 for NRM
        only) is the demag type (AF for alternating field, TT for thermal, CH for chemical, etc.), the next 4 (3 for
        NRM) is the demag level (Â°C for thermal, mT for alternating field, etc.), the next 6 (first blank for all the
        following fields) for geographic ("in situ") declination of the sample's magnetic vector, next 6 for geographic
        inclination, next 6 for stratigraphic declination, next 6 for stratigraphic inclination, next 9 for normalized
        intensity (emu/cm^3; multiply by the core volume/mass to get the actual measured core intensity), next 6 for
        measurement error angle, next 6 for core plate declination, next 6 for core plate inclination, and the final
        three fields of 8 each are the standard deviations of the measurement in the core's x, y, and z coordinates
        in 10^5 emu. NB in 2003, it appears the CIT format is actually using three final fields of 9 characters, not 8.

        Presently only the sample id line, the second line, and the first ten fields (to core inclination but
        excepting the error angle) of the demag lines are used in PaleoMag. Except for the stratigraphic level,
        info on the second line is only displayed in the info window or used in the "Headers..." command. A possibility
        exists that future versions will plot Zijder plots with the measurement uncertainties.

        Returns
        -------
            pd.DataFrame
        """

        with open(self.dfile) as f:
            raw_data = f.readlines()

        rows, raw_header_rows = self._separate_row(raw_data)

        self.header = self._read_header(raw_header_rows)

        data = pd.DataFrame(
            columns=['mtype', 'level', 'geo_dec', 'geo_inc', 'strat_dec', 'strat_inc', 'intensity', 'ang_err',
                     'plate_dec', 'plate_inc', 'std_x', 'std_y', 'std_z', 'user', 'date', 'time'], data=rows)

        data = dim2xyz(data, colD='plate_dec', colI='plate_inc', colM='intensity')
        data.loc[:, 'datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])
        data = data.set_index('datetime')
        return data

    """ properties """

    @property
    def geo_dim(self):
        """ Returns :obj:`pandas.DataFrame` of the geographic (dec, inc, intensity) """
        return self.data[['geo_dec', 'geo_inc', 'intensity']]

    @property
    def plate_dim(self):
        """ Returns :obj:`pandas.DataFrame` of the plate (dec, inc, intensity) """
        return self.data[['plate_dec', 'plate_inc', 'intensity']]

    @property
    def plate_xyz(self):
        """ Returns :obj:`pandas.DataFrame` of the plate (x,y,z) """
        return self.data[['x', 'y', 'z']]

    @property
    def geo_xyz(self):
        """ Returns :obj:`pandas.DataFrame` of the geographic (x,y,z) """
        return dim2xyz(self.geo_dim, colD='geo_dec', colI='geo_inc', colM='intensity')[['x', 'y', 'z']]

    def mean_levels(self):
        """ Calculates the mean of a level by from AF, UAFX1, UAFX2... measuements.

        Calculates the average for (AF, UAFX1, UAFX2, ...) of the same level and recalcuates the plate, core and strat
        declination and inclinations.

        Notes:
            `_mean_levels' can be used for testing purposes. This does not reset self.data with the means but returns a
            copy of the Dataframe.

        See Also:
            :py:meth:`RockPy.ftypes.cif.Cif._mean_levels`

        Returns"
            :obj:`pandas.DataFrame`: DataFrame with the mean of the data.
        """
        core_dip = self.header['core_dip']
        core_strike = self.header['core_strike']
        strat_dip = self.header['bedding_dip']
        strat_strike = self.header['bedding_strike']

        self.data = self._mean_levels(self.data,
                                      core_dip=core_dip, core_strike=core_strike,
                                      strat_dip=strat_dip, strat_strike=strat_strike)
        return self.data

    def reset_core_di(self):
        """ resets dec and inc in machine coordinates

        See Also:
            :py:meth:`RockPy.ftypes.cif.Cif._reset_plate` for the private method.

            :py:meth:`RockPy.ftypes.cif.Cif.reset_geo_di` to reset the geographic coordinates.

            :py:meth:`RockPy.ftypes.cif.Cif.reset_bedding_di` to reset the stratigraphic coordinates.

            uses: :py:func:`RockPy.tools.compute.xyz2dim`

        Returns:
            :obj:`pandas.DataFrame`: Data recalculated from x,y,z values
        """
        self.data = self._recalc_core_di(self.data)

    def reset_geo_di(self, dip=None, strike=None):
        """ resets dec and inc in geographic coordinates

        Args:
            dip (float, optional): defaults to the stored 'core_dip' value. Inclination of the core.
            strike (float, optional): defaults to the stored 'core_strike' value. Declination of the core.

        See Also:
            :py:meth:`RockPy.ftypes.cif.Cif._correct_core` for the private method that is called.

            uses: :py:func:`RockPy.tools.compute.xyz2dim`


        Returns:
            :obj:`pandas.DataFrame`: Data recalculated from x,y,z values
        """
        if dip is None:
            dip = self.header['core_dip']
        if strike is None:
            strike = self.header['core_strike']

        self.data = self._correct_core(self.data, dip, strike)
        self.header['core_dip'] = dip
        self.header['core_strike'] = strike

    def reset_bedding_di(self, dip=None, strike=None):
        """ resets dec and inc in stratigraphic coordinates

        Args:
            dip (float, optional): defaults to the stored 'core_dip' value. Inclination of the core.
            strike (float, optional): defaults to the stored 'core_strike' value. Declination of the core.

        See Also:
            :py:meth:`RockPy.ftypes.cif.Cif._correct_strat` for the private method that is called.

            uses: :py:func:`RockPy.tools.compute.xyz2dim`


        Returns:
            :obj:`pandas.DataFrame`: Data recalculated from x,y,z values
        """

        if dip is None:
            dip = self.header['bedding_dip'].values[0]
        if strike is None:
            strike = self.header['bedding_strike'].values[0]

        self.data = self._correct_strat(self.data, dip, strike)

    def correct_wrong_direction(self):
        self.data = self._correct_wrong_direction(df=self.data,
                                                  core_dip=self.header['core_dip'][0],
                                                  core_strike=self.header['core_strike'][0],
                                                  bedding_dip=self.header['bedding_dip'][0],
                                                  bedding_strike=self.header['bedding_strike'][0])

    def rotate_individual_measurement(self, indices, theta, axis):
        """

        Parameters
        ----------
        indices

        Returns
        -------

        """
        indices = RockPy.to_tuple(indices)
        indices = np.array(indices)

        data = self.data.iloc[indices]

        xyz = data[['x','y','z']].values
        xyz_ = data[['std_x','std_y','std_z']].values

        xyz_rotated = Rc.rotate(xyz=xyz, axis=axis, theta=theta)
        xyz__rotated = Rc.rotate(xyz=xyz_, axis=axis, theta=theta)

        self.data.loc[data.index, ['x','y','z']] = xyz_rotated
        self.data.loc[data.index, ['std_x','std_y','std_z']] = xyz__rotated

        self.reset_core_di()
        self.reset_geo_di()
        self.reset_bedding_di()

    def export(self, fname, sample_id=None, **kwargs):
        """
        Exports a cif file from the data
        Parameters
        ----------
        fname str
            where the data should be stored
        sample_id: name of the sample for the cif file
        """

        header = self.header.reset_index().iloc[0].to_dict()
        header.update(kwargs)
        if sample_id is not None:
            header['sample_id'] = sample_id

        data = self.data.copy()

        data = data.reset_index()

        with open(fname, 'w+') as f:
            header = self._write_header(**header)
            f.writelines(header)
            for row in data.iterrows():
                row = self._write_cif_line(row)
                f.write(row + '\n')

    def plot(self, fname = None):
        import RockPy.tools.plotting as rplt
        import matplotlib.pyplot as plt

        ax = [plt.subplot(121, projection='polar'),
              plt.subplot(122)]
        ax[0] = rplt.setup_stereonet(ax=ax[0])
        rplt.plot_equal(self.geo_xyz, color='C0', label='MIL 2.3', ax=ax[0])

        # Zydervelt
        norm = round(np.log10(self.geo_xyz[['x','y','z']].abs().max().max()))//3

        ax[1].plot(self.geo_xyz.iloc[:-1]['y'] / 10 ** (norm*3),
                   self.geo_xyz.iloc[:-1]['x'] / 10 ** (norm*3),
                   marker='o', ls='-', label='y/x (dec)', markevery=1, mfc='w')
        ax[1].plot(self.geo_xyz.iloc[:-1]['y'] / 10 ** (norm*3),
                   self.geo_xyz.iloc[:-1]['z'] / 10 ** (norm*3),
                   marker='o', ls='-', label='y/z (inc)', markevery=1)

        ax[1].plot([], [], marker='s', mfc='w', color='k')

        ax[1].set_xlabel(f'E ($10^{{{norm*3}}}$ Am$^2$/kg)')
        ax[1].set_ylabel(f'N/up ($10^{{{norm*3}}}$ Am$^2$/kg)', rotation=-90)

        ax[1].xaxis.set_ticks_position('bottom')
        ax[1].yaxis.set_ticks_position('left')

        # ax[1].spines['left'].set_position('zero')
        ax[1].spines['right'].set_color('none')
        # ax[1].spines['bottom'].set_position('zero')
        ax[1].spines['top'].set_color('none')

        plt.tight_layout()
        if fname is not None:
            f.savefig(fname)
        plt.show()
class Cif(Cit):
    def __init__(self, dfile,
                 snames=None, reload=False,
                 mdata=None, create_minfo=True,
                 level_unit='gauss', dialect=None,
                 **kwargs):
        """
        Constructor for the Cif file type. Reads cif files as generated by the 2G rapid system, for example.
        Generally agnostic to the measurement type.

        Args:
            dfile (str): full path to file on HD
            snames (str, optional): defaults to None
                sample name
            reload (bool, optional): defaults to True.
                if True the file will be re-imported from HD
                if False RockPy will attempt to read the file from cache
            mdata (:obj:`pd.DataFrame`, optional): defaults to None. Used for creation of cif from several
                files (i.e. UP) using from_file method
            create_minfo (bool, optional): if False creation of ImportHelper object is suppressed;
                if True RockPy will try to create ImportHelper object
            level_unit(str, optional): defaults to 'G'. Determines the unit for the level. May be ËšC, G, ...
            **kwargs: arbitrary keyword arguments
        """
        self.log().warning('This class has been deprecated, use << cit >> instead!')

        # call the ftype constructor
        super().__init__(dfile, snames=snames,
                         dialect=None, reload=reload,
                         mdata=mdata, create_minfo=create_minfo,
                         **kwargs)

if __name__ == '__main__':
    d = Cit('/Users/mike/Dropbox/science/harvard/2G_data/mike/MIL/NRM_ARM_IRM/MIL14_IRM')
    d.rotate_individual_measurement([1,2], 20, 'z')
    # print(Rc.rotate([0.1899985356159913,-0.02805654275408272,1.366569934863367],axis='z',theta=20))
